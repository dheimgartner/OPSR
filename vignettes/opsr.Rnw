\documentclass[article,nojss]{jss}

%% -- LaTeX packages and custom commands ---------------------------------------

%% recommended packages
\usepackage{orcidlink,thumbpdf,lmodern}

%% another package (only for the draft article)
\usepackage{framed}

%% daniehei
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{dcolumn}

%% new custom commands
\newcommand{\class}[1]{`\code{#1}'}
\newcommand{\fct}[1]{\code{#1()}}

%%daniehei
\newcommand{\jth}{\ensuremath{j^{\mathrm{th}}\,}}  % jth will never follow by punctuation
\newcommand{\Xb}{\boldsymbol{X_j}\boldsymbol{\beta_j}}
\newcommand{\Xbd}{\boldsymbol{X_{j'}}\boldsymbol{\beta_{j'}}}
\newcommand{\Wg}{\boldsymbol{W}\boldsymbol{\gamma}}

%% For Sweave-based articles about R packages:
%% need no \usepackage{Sweave}
\SweaveOpts{engine=R, eps=FALSE, keep.source = TRUE}
<<preliminaries, echo=FALSE, results=hide>>=
library(OPSR)

options(prompt = "R> ", continue = "+  ", width = 70, useFancyQuotes = FALSE,
        digits = 3)
@


%% -- Article metainformation (author, title, ...) -----------------------------

%% - \author{} with primary affiliation (and optionally ORCID link)
%% - \Plainauthor{} without affiliations
%% - Separate authors by \And or \AND (in \author) or by comma (in \Plainauthor).
%% - \AND starts a new line, \And does not.
\author{Daniel Heimgartner~\orcidlink{0000-0002-0643-8690}\\ETH Z\"urich
\And Xinyi Wang~\orcidlink{0000-0002-3564-9147}\\MIT Boston}
\Plainauthor{Daniel Heimgartner, Xinyi Wang}

%% - \title{} in title case
%% - \Plaintitle{} without LaTeX markup (if any)
%% - \Shorttitle{} with LaTeX markup (if any), used as running title
\title{\pkg{OPSR}: A Package for Estimating Ordinal Probit Switching Regression Models in \proglang{R}}
\Plaintitle{OPSR: A Package for Estimating Ordinal Probit Switching Regression Models in R}
\Shorttitle{\pkg{OPSR}: Ordinal Probit Switching Regression in \proglang{R}}

%% - \Abstract{} almost as usual
\Abstract{
When treatment is endogenous, selection bias might arise if unobserved factors simultaneously influence both the selection and outcome process. A possible cure in the case of cross-sectional data is to explicitly account for this error correlation and estimate the covariance matrix of the two processes. This is known as endogenous switching regression. The \proglang{R} package \pkg{OPSR} introduced in this article provides an easy-to-use, fast and memory efficient interface to ordinal probit switching regression, accounting for self-selection into an ordinal treatment. It handles log-transformed outcomes which need special consideration when computing conditional expectations and thus treatment effects.
}

%% - \Keywords{} with LaTeX markup, at least one required
%% - \Plainkeywords{} without LaTeX markup (if necessary)
%% - Should be comma-separated and in sentence case.
\Keywords{ordinal probit switching regression, endogenous switching regression, Heckman selection, selection bias, treatment effect, \proglang{R}}
\Plainkeywords{ordinal probit switching regression, endogenous switching regression, Heckman selection, selection bias, treatment effect, R}

%% - \Address{} of at least one author
%% - May contain multiple affiliations for each author
%%   (in extra lines, separated by \emph{and}\\).
%% - May contain multiple authors for the same affiliation
%%   (in the same first line, separated by comma).
\Address{
Daniel Heimgartner\\
Institute for Transport Planning and Systems\\
Eidgen\"ossische Technische Hochschule Z\"urich\\
IFW C 46.1\\
Haldeneggsteig 4\\
8092 Z\"urich, Switzerland\\
E-mail: \email{daniel.heimgartner@ivt.baug.ethz.ch}\\
\\
Xinyi Wang\\
Department of Urban Studies and Planning\\
Massachusetts Institute of Technology\\
105 Massachusetts  Avenue\\
Cambridge, MA 02139\\
E-mail: \email{xinyi174@mit.edu}
}

\begin{document}


%% -- Introduction -------------------------------------------------------------

%% - In principle "as usual".
%% - But should typically have some discussion of both _software_ and _methods_.
%% - Use \proglang{}, \pkg{}, and \code{} markup throughout the manuscript.
%% - If such markup is in (sub)section titles, a plain text version has to be
%%   added as well.
%% - All software mentioned should be properly \cite-d.
%% - All abbreviations should be introduced.
%% - Unless the expansions of abbreviations are proper names (like "Journal
%%   of Statistical Software" above) they should be in sentence case (like
%%   "generalized linear models" below).

\section{Introduction} \label{sec:intro}

The goal of the program evaluation literature is to estimate the effect of a treatment program (e.g., a new policy, technology, medical treatment, or agricultural practice) on an outcome. To evaluate such a program, the ``treated'' are compared to the ``untreated''. In an experimental setting, the treatment can be assigned by the researcher. However, in an observational setting, the treatment is not always exogeneously prescribed but rather self-selected. This gives rise to a selection bias when unobserved factors influencing the treatment adoption also influence the outcome (also known as \emph{selection on unobservables}). Simple group comparison no longer yield an unbiased estimate of the treatment effect. In more technical terms, the counterfactual outcome of the treated (``if they had not been treated'') does not necessarily correspond to the factual outcome of the untreated. For example, cyclists riding without a helmet (the ``untreated'') might have a risk-seeking tendency. We therefore potentially overestimate the benefit of wearing a helmet if we compare the accident (severity) rate of the two groups. Risk-seeking is not readily measured and it is easy to imagine that it becomes part of the error in applied research and thus leading cause of a selection bias.

To properly account for the selection bias, various techniques exist, both for longitudinal and cross-sectional data. In the first case, difference in differences is a widely adopted measure. In the latter case, instrumental variables, matching propensity scores, regression-discontinuity design, and the endogenous switching regression model have been applied \citep{Wang+Mokhtarian:2024}. The latter method is particularly well-suited to correct for selection on unobservables (unlike other methods which only address and correct for selection on observables).

The seminal work by \cite{Heckman:1979} proposed a two-part model to address the selection bias that often occurs when modelling a continuous outcome which is only observable for a subpopulation. A very nice exposition of this model is given in \citet[][Chapter~16]{Cameron+Trivedi:2005}. The classical Heckman model consists of a probit equation and continuous outcome equation. A natural extension is then switching regression, where the population is partitioned into different groups (regimes) and separate parameters are estimated for the continuous outcome process of each group. This model is originally known as the Roy model \citep{Cameron+Trivedi:2005} or Tobit 5 model \citep{Amemiya:1985}. These classical models (the Tobit models for truncated, censored or interval data and their extensions) are implemented in various environments for statistical computing and in \proglang{R}'s \citep{R} \pkg{sampleSelection} package \citep{Toomet+Henningsen:2008}.

Many different variants can then be derived by either placing different distributional assumptions on the errors and/or how the latent process manifests into observed outcomes (i.e., the dependent variables can be of various types, such as binary, ordinal, censored, or continuous) more generally known as conditional mixed-process (CMP) models. CMP models comprise a broad family involving two or more equations featuring a joint error distribution assumed to be multivariate normal. The \proglang{Stata} \citep{Stata} command \code{cmp} \citep{Roodman:2011} can fit such models. The variant at the heart of this paper is an ordinal probit switching regression (OPSR) model, with an ordered treatment and continuous outcome. Throughout the text we use the convention that OPSR refers to the general methodology, while \pkg{OPSR} refers specifically to the package.

OPSR is available as a \proglang{Stata} command, \code{oheckman} \citep{Chiburis+Lokshin:2007}, which however, does not allow distinct specifications for the continuous outcome processes (i.e., the same explanatory variables must be used for all treatment groups). The relatively new \proglang{R} package \pkg{switchSelection} \citep{Potanin:2024} allows to estimate multivariate and multinomial sample selection and endogenous switching models with multiple outcomes. These models are systems of ordinal, continuous and multinomial equations and thus nest OPSR as a special case.

\pkg{OPSR} is tailored to one particular method, easy to use (understand, extend and maintain), fast and memory efficient. It handles log-transformed continuous outcomes which need special consideration for the computation of conditional expectations. It obeys to \proglang{R}'s implicit modeling conventions (by extending the established generics such as \fct{summary}, \fct{predict}, \fct{update}, \fct{anova} among others) and produces production-grade output tables. This work generalizes the learnings from \cite{Wang+Mokhtarian:2024} and makes the OPSR methodology readily available. The mathematical notation presented here translates to code almost verbatim which hopefully serves a pedagogical purpose for the curious reader.


%% -- Manuscript ---------------------------------------------------------------

%% - In principle "as usual" again.
%% - When using equations (e.g., {equation}, {eqnarray}, {align}, etc.
%%   avoid empty lines before and after the equation (which would signal a new
%%   paragraph.
%% - When describing longer chunks of code that are _not_ meant for execution
%%   (e.g., a function synopsis or list of arguments), the environment {Code}
%%   is recommended. Alternatively, a plain {verbatim} can also be used.
%%   (For executed code see the next section.)

\section{Model and software} \label{sec:model}

In the following, we outline the ordinal probit switching regression model as well as list all the key formulas underlying the software implementation. \pkg{OPSR} follows the \proglang{R}-typical formula interface to a workhorse fitter function. Its architecture is detailed after the mathematical part.

As alluded, OPSR is a two-step model: One process governs the ordinal outcome and separate processes (for each ordinal outcome) govern the continuous outcomes. The ordinal outcome can also be thought of as a regime or treatment. In the subsequent exposition, we will refer to the two processes as \emph{selection} and \emph{outcome} process.

We borrow the notation from \cite{Wang+Mokhtarian:2024} where also all the derivations are detailed. For a similar exhibition, \citet{Chiburis+Lokshin:2007} can be consulted. Individual subscripts are suppressed throughout, for simplicity.

Let $\mathcal{Z}$ be a latent propensity governing the selection outcome
%
\begin{equation} \label{eq:selection}
\mathcal{Z} = \Wg + \epsilon,
\end{equation}
%
where $\boldsymbol{W}$ represents the vector of attributes of an individual, $\boldsymbol{\gamma}$ is the corresponding vector of parameters and $\epsilon \sim \mathcal{N}(0, 1)$ a normally distributed error term.

As $\mathcal{Z}$ increases and passes some unknown but estimable thresholds, we move up from one ordinal treatment to the next higher level
%
\begin{equation} \label{eq:thresholds}
Z = j \quad \mathrm{if}\ \kappa_{j-1} < \mathcal{Z} \le \kappa_j,
\end{equation}
%
where $Z$ is the observed ordinal selection variable, $j = 1, \dots, J$ indexes the ordinal levels of $Z$, and $\kappa_j$ are the thresholds (with $\kappa_0 = -\infty$ and $\kappa_J = \infty$). Hence, there are $J-1$ thresholds to be estimated. The probability that an individual self-selects into treatment group $j$ is
%
\begin{equation} \label{eq:prob-selection}
\begin{aligned}
\Prob[Z = j] &= \Prob[\kappa_{j-1} < \mathcal{Z} \le \kappa_j] \\
&= \Prob[\kappa_{j-1} - \Wg < \epsilon \le \kappa_j - \Wg] \\
&= \Phi(\kappa_j - \Wg) - \Phi(\kappa_{j-1} - \Wg).
\end{aligned}
\end{equation}

The outcome model for the \jth treatment group is expressed as
%
\begin{equation} \label{eq:outcome}
y_j = \Xb + \eta_j,
\end{equation}
%
where $y_j$ is the observed continuous outcome, $\boldsymbol{X_j}$ the vector of observed explanatory variables associated with the \jth outcome model, $\boldsymbol{\beta_j}$ is the vector of associated parameters, and $\eta_j \sim \mathcal{N}(0, \sigma^2)$ is a normally distributed error term. At this point it should be noted that $\boldsymbol{X_j}$ and $\boldsymbol{W}$ may share some explanatory variables but not all, due to identification problems otherwise \citep{Chiburis+Lokshin:2007}.

The key assumption of OPSR is now that the errors of the selection and outcome models are jointly multivariate normally distributed
%
\begin{equation} \label{eq:multi-norm}
\begin{pmatrix}
\epsilon \\
\eta_1 \\
\vdots \\
\eta_j \\
\vdots \\
\eta_J
\end{pmatrix}
\sim \mathcal{N}\left(
\begin{pmatrix}
0 \\
0 \\
\vdots \\
0 \\
\vdots \\
0
\end{pmatrix},
\begin{pmatrix}
1 & \rho_1 \sigma_1 & \cdots & \rho_j \sigma_j & \cdots & \rho_J \sigma_J \\
\rho_1 \sigma_1 & \sigma_2^2 \\
\vdots &  & \ddots \\
\rho_j \sigma_j & & & \sigma_j^2 \\
\vdots & & & & \ddots \\
\rho_J \sigma_J & & & & & \sigma_J^2
\end{pmatrix}
\right),
\end{equation}
%
where $\rho_j$ represents the correlation between the errors of the selection model ($\epsilon$) and the \jth outcome model ($\eta_j$). If the covariance matrix should be diagonal (i.e., no error correlation), no selection-bias exists and the selection and outcome models can be estimated separately.

As shown in \cite{Wang+Mokhtarian:2024}, the log-likelihood of observing all individuals self-selecting into treatment $j$ and choosing continuous outcome $y_j$ can be expressed as
%
\begin{multline} \label{eq:log-lik}
\ell(\theta \mid \boldsymbol{W}, \boldsymbol{X_j}) = \sum_{j = 1}^{J} \sum_{\{j\}}
\left\{
\ln\left[
\frac{1}{\sigma_j} \phi\left(\frac{y_j - \Xb}{\sigma_j}\right)
\right] \quad + \right. \\
\left. \ln\left[
\Phi\left(
\frac{\sigma_j (\kappa_j - \Wg) - \rho_j(y_j - \Xb)}{\sigma_j\sqrt{1 - \rho_j^2}}
\right) -
\Phi\left(
\frac{\sigma_j (\kappa_{j-1} - \Wg) - \rho_j(y_j - \Xb)}{\sigma_j\sqrt{1 - \rho_j^2}}
\right)
\right]
\right\}
\end{multline}
%
where $\sum_{\{j\}}$ means the summation of all the cases belonging to the \jth selection outcome, $\phi(\cdot)$ and $\Phi(\cdot)$ are the density and cumulative distribution function of the standard normal distribution.

The conditional expectation can be expressed as
%
\begin{equation} \label{eq:cond-exp}
\begin{aligned}
\E[y_j \mid Z = j] &= \Xb + \E[\eta_j \mid \kappa_{j-1} - \Wg < \epsilon \le \kappa_j - \Wg] \\
&= \Xb - \rho_j\sigma_j \frac{\phi(\kappa_j - \Wg) - \phi(\kappa_{j-1} - \Wg)}{\Phi(\kappa_j - \Wg) - \Phi(\kappa_{j-1} - \Wg)},
\end{aligned}
\end{equation}
%
where the fraction is the ordered probit switching regression model counterpart to the inverse Mills ratio (IMR) term of a binary switching regression model. We immediately see, that regressing $\boldsymbol{X_j}$ on $y_j$ leads to an omitted variable bias if $\rho_j \neq 0$ which is the root cause of the selection bias. However, the IMR can be pre-computed based on an ordinal probit model and then included in the second stage regression, which describes the Heckman correction \citep{Heckman:1979}. It should be warned, that since the Heckman two-step procedure includes an estimate in the second step regression, the resulting OLS standard errors and heteroskedasticity-robust standard errors are incorrect \citep{Greene:2002}.

To obtain unbiased treatment effects, we must further evaluate the ``counterfactual outcome'', which reflects the expected outcome under a counterfactual treatment (i.e., for $j' \neq j$)
%
\begin{equation} \label{eq:counterfact-exp}
\begin{aligned}
\E[y_{j'} \mid Z = j] &= \Xbd + \E[\eta_{j'} \mid \kappa_{j-1} - \Wg < \epsilon \le \kappa_j - \Wg] \\
&= \Xbd - \rho_{j'}\sigma_{j'} \frac{\phi(\kappa_j - \Wg) - \phi(\kappa_{j-1} - \Wg)}{\Phi(\kappa_j - \Wg) - \Phi(\kappa_{j-1} - \Wg)}.
\end{aligned}
\end{equation}

As it is usual to log-transform the continuous outcome in regression analysis, we have to note, that in such cases the Equations~\ref{eq:cond-exp}-\ref{eq:counterfact-exp} provide the conditional expectation of the log-transformed outcome. Therefore, we need to back-transform $\ln(y_j + 1)$ which yields
%
\begin{equation} \label{eq:log-cond-exp}
\E[y_j \mid Z = j] =
\exp\left(\Xb + \frac{\sigma_j^2}{2}\right)
\left[
\frac{\Phi(\kappa_j - \Wg - \rho_j\sigma_j) - \Phi(\kappa_{j-1} - \Wg - \rho_j\sigma_j)}
{\Phi(\kappa_j - \Wg) - \Phi(\kappa_{j-1} - \Wg)}
\right] - 1
\end{equation}
%
for the factual case, and
%
\begin{equation} \label{eq:log-counterfact-exp}
\E[y_{j'} \mid Z = j] =
\exp\left(\Xbd + \frac{\sigma_{j'}^2}{2}\right)
\left[
\frac{\Phi(\kappa_j - \Wg - \rho_{j'}\sigma_{j'}) - \Phi(\kappa_{j-1} - \Wg - \rho_{j'}\sigma_{j'})}
{\Phi(\kappa_j - \Wg) - \Phi(\kappa_{j-1} - \Wg)}
\right] - 1
\end{equation}
%
for the counterfactual case \citep{Wang+Mokhtarian:2024}.

This concludes the mathematical treatment and we briefly outline \pkg{OPSR}'s architecture which can be conceptualized as follows:
\begin{itemize}
\item We provide the usual formula interface to specify a model. To allow for multiple parts and multiple responses, we rely on the \pkg{Formula} package \citep{Zeileis+Croissant:2010}.
\item After parsing the formula object, checking the user inputs and computing the model matrices, the Heckman two-step estimator is called in \fct{opsr\_2step} to generate reasonable starting values.
\item These are then passed together with the data to the basic computation engine \fct{opsr.fit}. The main estimates are retrieved using maximum likelihood estimation by passing the log-likelihood function \fct{loglik\_cpp} (Equation~\ref{eq:log-lik}) to \fct{maxLik} from the \pkg{maxLik} package \citep{Henningsen+Toomet:2011}.
\item All the above calls are nested in the main interface \fct{opsr} which returns an object of class \class{opsr}. Several methods then exist to post-process this object as illustrated below.
\end{itemize}

The likelihood function \fct{loglik\_cpp} is implemented in \proglang{C++} using \pkg{Rcpp} \citep{Edelbuettel+Balamuta:2018} and relying on the data types provided by \pkg{RcppArmadillo} \citep{Edelbuettel+Sanderson:2014}. Parallelization is available using \proglang{OpenMP}. This makes \pkg{OPSR} both fast and memory efficient (as data matrices are passed by reference).


%% -- Illustrations ------------------------------------------------------------

%% - Virtually all JSS manuscripts list source code along with the generated
%%   output. The style files provide dedicated environments for this.
%% - In R, the environments {Sinput} and {Soutput} - as produced by Sweave() or
%%   or knitr using the render_sweave() hook - are used (without the need to
%%   load Sweave.sty).
%% - Equivalently, {CodeInput} and {CodeOutput} can be used.
%% - The code input should use "the usual" command prompt in the respective
%%   software system.
%% - For R code, the prompt "R> " should be used with "+  " as the
%%   continuation prompt.
%% - Comments within the code chunks should be avoided - these should be made
%%   within the regular LaTeX text.

\section{Illustrations} \label{sec:illustrations}

We first illustrate how to specify a model using \pkg{Formula}'s extended syntax and simulated data. Then the main functionality of the package is demonstrated. We conclude this section by demonstrating some nuances, reproducing the core model of \cite{Wang+Mokhtarian:2024}.

Let us simulate date from an OPSR process with three ordinal outcomes and distinct design matrices $\boldsymbol{W}$ and $\boldsymbol{X}$ (where $\boldsymbol{X} = \boldsymbol{X_j} \ \forall{j}$) by
%
<<sim-dat>>=
sim_dat <- opsr_simulate()
dat <- sim_dat$data
head(dat)
@
%
where \code{ys} is the selection outcome (or treatment group), \code{yo} the continuous outcome and \code{xs} respectively \code{xo} the corresponding explanatory variables.

Models are specified symbolically. A typical model has the form \code{ys | yo ~ terms_s | terms_o1 | terms_o2 | ...} where the \code{|} separates the two responses and process specifications. If the user wants to specify the same process for all continuous outcomes, two processes are enough (\code{ys | yo ~ terms_s | terms_o}). Hence the minimal \fct{opsr} interface call reads
%
<<opsr>>=
fit <- opsr(ys | yo ~ xs1 + xs2 | xo1 + xo2, data = dat,
  printLevel = 0)
@
%
where \code{printLevel = 0} omits working information during maximum likelihood iterations.

As usual, the fitter function does the bare minimum model estimation while inference is performed in a separate call
%
<<summary-xinyi>>=
summary(fit)
@
%
The presentation of the model results is fairly standard and should not warrant further explanation with the following exceptions
\begin{enumerate}
\item The number of regimes along absolute counts are reported.
\item Coefficient names are based on the variable names as passed to the formula specification, except that \code{"s_"} is prepended to the selection coefficients, \code{"o[0-9]_"} to the outcome coefficients and the structural components \code{"kappa", "sigma", "rho"} (aligning with the letters used in Equation~\ref{eq:log-lik}) are hard-coded (but can be over-written).
\item The coefficients table reports robust standard errors based on the sandwich covariance matrix as computed with help of the \pkg{sandwich} package \citep{Zeileis:2006}. \code{rob = FALSE} reports conventional standard errors.
\item Two Welch-tests are conducted. One, testing the null that all coefficients of explanatory variables are zero and two, testing the null that all error correlation coefficients ($\rho$) are zero. If the latter is rejected, selection bias is not an issue.
\end{enumerate}

A useful benchmark is always the null model with structural parameters only. The null model can be derived from an \class{opsr} model fit as follows
%
<<null-model>>=
fit_null <- opsr_null_model(fit, printLevel = 0)
@

A model can be updated as usual
%
<<update>>=
fit_intercept <- update(fit, . ~ . | 1)
@
%
where we have removed all the explanatory variables from the outcome processes.

Several models can be compared with a likelihood-ratio test using
%
<<anova>>=
anova(fit_null, fit_intercept, fit)
@
%
If only a single object is passed, then the model is compared to the null model. If more than one object is specified a likelihood ratio test is conducted for each pair of neighboring models. As expected, both tests reject the null.

Models can be compared side-by-side using the \pkg{texreg} package \citep{Leifeld:2013}, which also allows the user to build production-grade tables as illustrated later.
%
<<texreg>>==
texreg::screenreg(list(fit_null, fit_intercept, fit),
  include.pseudoR2 = TRUE, include.R2 = TRUE, single.row = TRUE)
@

Finally, the key interest of an OPSR study almost certainly is the estimation of treatment effects which relies on (counterfactual) conditional expectations as already noted in the mathematical exposition.
%
<<predict>>==
p1 <- predict(fit, group = 1, type = "response")
p2 <- predict(fit, group = 1, counterfact = 2, type = "response")
@
%
where \code{p1} is the result of applying Equation~\ref{eq:cond-exp} and \code{p2} is the counterfactual outcome resulting from Equation~\ref{eq:counterfact-exp}. The following \code{type} arguments are available
\begin{itemize}
\item \code{type = "response"}: Predicts the continuous outcome according to the Equations referenced above.
\item \code{type = "unlog-response"}: Predicts the back-transformed response if the continuous outcome was log-transformed according to Equations~\ref{eq:log-cond-exp}-\ref{eq:log-counterfact-exp}.
\item \code{type = "prob"}: Returns the probability vector of belonging to \code{group}.
\item \code{type = "mills"}: Returns the inverse Mills ratio.
\end{itemize}
Elements are \code{NA_real_} if the \code{group} does not correspond to the observed regime (selection outcome). This ensures consistent output length.

Now that the user understands the basic workflow, we illustrate some nuances by reproducing a key output of \cite{Wang+Mokhtarian:2024} where they investigate the treatment effect of telework on weekly vehicle miles driven. The data is attached, documented (\code{?telework_data}) and can be loaded by
%
<<telework-data>>=
data("telework_data", package = "OPSR")
@

<<hidden, echo=FALSE>>=
start <- c(
  1.2, 2.4,  # kappa 1 & 2
  0.2, 0.4, 0.1, 0.3, 0.3, 0.2, 0.1, 0.1, -0.1, 0.1, 0.1, 0.3, 0.1, 0.1,  # selection
  3.744, -0.208, 0.010, 0.000, -0.392, -0.019, 0.130, 0.010, 0.415, 0.494, 0.437, 0.186, 0.124, -0.240,  # outcome 1
  2.420, 0.224, 0.670, 0.445, 0.219, 0.824, 0.704, 0.164, -0.176, 0.171,  # outcome 2
  2.355, -0.375, 0.476, 0.317, 0.187, 0.290, 0.313, 0.856, 0.248, -0.275,  # outcome 3
  1.193, 1.248, 1.413,  # sigma
  0.068, 0.128, 0.340  # rho
)
@

The final model specification reads
%
<<formula-xinyi>>=
f <-
  twing_status | vmd_ln ~
  edu_2 + edu_3 + hhincome_2 + hhincome_3 + flex_work + work_fulltime +
  twing_feasibility + att_proactivemode + att_procarowning + att_wif +
  att_proteamwork + att_tw_effective_teamwork + att_tw_enthusiasm +
  att_tw_location_flex |
  female + age_mean + age_mean_sq + race_black + race_other + vehicle +
  suburban + smalltown + rural + work_fulltime + att_prolargehouse +
  att_procarowning + region_waa |
  edu_2 + edu_3 + suburban + smalltown + rural + work_fulltime +
  att_prolargehouse + att_proactivemode + att_procarowning |
  female + hhincome_2 + hhincome_3 + child + suburban + smalltown +
  rural + att_procarowning + region_waa
@
%
and the model can be estimated by
%
<<model-xinyi>>=
start_default <- opsr(f, telework_data, .get2step = TRUE)
fit <- opsr(f, telework_data, start = start, method = "NM", iterlim = 50e3,
            printLevel = 0)
@
%
where we demonstrate that
\begin{enumerate}
\item Default starting values as computed by the Heckman two-step procedure can be retrieved.
\item \code{start} values can be overridden (we have hidden the \code{start} vector here for brevity). If the user wishes to pass start values manually, some minimal conventions have to be followed as documented in \code{?opsr_check_start}.
\item Alternative maximization methods (here ``Nelder-Mead'') can be used (as in the original paper).
\end{enumerate}

<<hidden, echo=FALSE>>=
custom.model.names <- c("NTWer (535)", "NUTWer (322)", "UTWer (727)")
custom.coef.names <- c(
  "Intercept",
  "Female",
  "Age",
  "Age squared",
  "Black",
  "Other races",
  "Number of vehicles",
  "Suburban",
  "Small town",
  "Rural",
  "Full time worker",
  "Pro-large-house",
  "Pro-car-owning",
  "Region indicator (WAA)",
  "Some college",
  "Bachelor's degree or higher",
  "Pro-active-mode",
  "\\$50,000 to \\$99,999",
  "\\$100,000 or more",
  "Number of children"
)
reorder.coef <- c(1, 2, 3, 4, 5, 6, 15, 16, 18, 19, 20, 7, 8, 9, 10, 11, 12, 13, 17, 14)
groups <- list(
  "Race (ref: white)" = 5:6,
  "Education (ref: high school or less)" = 7:8,
  "Annual household income (ref: less than \\$50,000)" = 9:10,
  "Residential location (ref: urban)" = 13:15,
  "Attitudes" = 17:19
)
@

With help of the \pkg{texreg} package, production-grade tables (in various output formats) can be generated with ease.
%
<<replica, results=tex>>=
texreg::texreg(
  fit, beside = TRUE, include.structural = FALSE,
  include.selection = FALSE, include.R2 = TRUE,
  custom.model.names = custom.model.names,
  custom.coef.names = custom.coef.names,
  single.row = TRUE,
  reorder.coef = reorder.coef, groups = groups, scalebox = 0.86,
  booktabs = TRUE, dcolumn = TRUE, use.packages = FALSE, float.pos = "t!",
  caption = "Replica of \\cite{Wang+Mokhtarian:2024}, Table 3.",
  label = "tab:wang-replica"
)
@
%
Dot arguments (\code{...}) passed to \fct{texreg} (or similar functions) are forwarded to a \proglang{S4} method \fct{extract} which extracts the variables of interest from a model fit (see also \code{?extract.opsr}). We demonstrate here that
\begin{enumerate}
\item The structural coefficients ($\kappa$, $\sigma$ and $\rho$) and coefficients belonging to the selection component can be omitted (\code{include.structural = FALSE}, \code{include.selection = FALSE}).
\item The model components can be printed side-by-side (\code{beside = TRUE}).
\item Additional goodness-of-fit indicators can be included (\code{include.R2 = TRUE}).
\item The output formatting can be controlled flexibly, by reordering, renaming and grouping coefficients (the fiddly but trivial details are hidden here for brevity).
\end{enumerate}


%% -- Case study ---------------------------------------------------------------
\section{Case study} \label{sec:case-study}

Now that the reader is familiar with the main functionality of \pkg{OPSR}, this section demonstrates how to use it in a real-world example. The emphasis, therefore, lies not on what each function does but on guiding the reader through the modeling and post-estimation steps. We investigate once again, telework treatment effects on weekly distance traveled (aggregated over all modes of transport).

%% The data
We use the TimeUse+ dataset \citep{Winkler+Meister+Axhausen:2024}, a smartphone-based diary, recording travel, time use, and expenditure data. Our analytical sample comprises employed individuals only and is based on what \citet{Winkler+Axhausen:2024} identified as valid days. A valid day has at least 20 hours of information where 70\% of the events were validated by the user. Users who did not have at least 14 valid days were excluded and for the remaining 824 participants mobility indicators for a typical week were constructed. The telework status is based on tracked (and labelled) work activities and we differentiate three regimes: Non-teleworkers (NTW), Non-usual teleworkers (NUTW; $<$3 days/week) and Usual teleworkers (UTW; 3$+$ days/week).

The data, underlying this analysis, is attached, documented (\code{?timeuse_data}) and can be loaded by
%
<<timeuse-data>>=
data("timeuse_data", package = "OPSR")
@

A basic boxplot of the response variable against the three teleworking status is displayed in Figure~\ref{fig:boxplot}. By simply looking at the data descriptively, we might prematurely conclude that telework does not impact weekly distance traveled. However, the whole value proposition of OPSR (and for models in general) is that we really are interested in a counterfactual. If the teleworkers self-select, the counterfactual is not simply the group average. More prosaically, if the usual telewokers (UTW) would choose to be non-teleworkers (NTW), they might travel more or less than the actual NTWs.

Meanwhile, commute distance increases across the three teleworking groups, suggesting that teleworkers ``compensate'' some of the foregone commute with leisure travel.

\setkeys{Gin}{width=.8\textwidth}
\begin{figure}[t!]
\centering
<<boxplot, echo=FALSE, fig=TRUE, height=5, width=9>>=
par(mfrow = c(1, 2))
plot(log_weekly_km ~ factor(wfh), data = timeuse_data, varwidth = TRUE,
     ylab = "Log weekly distance traveled (km)", xlab = "Teleworking status",
     names = c("NTW", "NUTW", "UTW"), main = "Weekly distance traveled",
     col = "white")
plot(log_commute_km ~ factor(wfh), data = timeuse_data, varwidth = TRUE,
     ylab = "Log commute distance (km)", xlab = "Teleworking status",
     names = c("NTW", "NUTW", "UTW"), main = "Commute distance",
     col = "white")
@
\caption{\label{fig:boxplot} Log weekly distance traveled for different teleworking status.}
\end{figure}

%% The model
Before blindly throwing all variables at \pkg{OPSR} the modeler is well advised to first, think of an identification restriction as discussed in Section~\ref{sec:model} and second, estimate the models separately, e.g., using \fct{polr} from the \pkg{MASS} package \citep{Venables+Ripley:2002}, and \fct{lm} for the treatment groups separately. We reserve the international standard classification of occupations (ISCO-08) variables for the selection process.
%
<<fit-polr>>=
drop <- c("id", "weekly_km", "log_weekly_km", "commute_km", "log_commute_km",
  "wfh_days")
dat_polr <- subset(timeuse_data, select = !(names(timeuse_data) %in% drop))
dat_polr$wfh <- factor(dat_polr$wfh)
fit_polr <- MASS::polr(wfh ~ ., dat_polr, method = "probit")
@

We use the \fct{stepAIC} function to choose a selection model specification by AIC in a stepwise algorithm
%
<<step>>=
fit_step <- MASS::stepAIC(fit_polr, trace = FALSE)
fit_step$anova
@
%
The selected model can also be fitted with \fct{opsr}, specifying a constant for all continuous outcomes
%
<<fit-selection>>=
f_step <- wfh | log_weekly_km ~
  age + educ_higher + hh_income + young_kids + workload + fixed_workplace +
  shift_work + permanent_employed + isco_craft + isco_tech + isco_clerical +
  isco_elementary + car_access + parking_home + freq_onl_order +
  grocery_shopper |
  1
fit_step2 <- opsr(f_step, timeuse_data, printLevel = 0)
@

Fitting the linear models separately, has the advantage that the analyst gets aware of potential identification problems (e.g., colinear variables or missing factor levels in one of the groups). While the resulting estimates are potentially biased and their standard errors not reliable it can still be beneficial to investigate the estimates.
%
<<fit-outcome>>=
fit_lm <- function(data, group) {
  f <- paste0("log_weekly_km ~ . - wfh")
  dat <- subset(data, subset = wfh == group)
  fit <- lm(f, dat)
  fit
}

drop <- c("id", "weekly_km", "commute_km", "log_commute_km", "wfh_days")
dat_lm <- subset(timeuse_data,
  select = !(names(timeuse_data) %in% drop) & !grepl("^isco_", names(timeuse_data)))

fit_ntw <- fit_lm(dat_lm, group = 1)
fit_nutw <- fit_lm(dat_lm, group = 2)
fit_utw <- fit_lm(dat_lm, group = 3)
@
%
For example, looking at \code{summary(fit_utw)} yields the insight, that we have two identification issues for the UTW: First \code{shift_work} is a constant and second \code{parking_home} is colinear with \code{car_access}.

We then follow the conventional (somewhat heuristic) model building strategy to specify the full identified model and then exclude all variables which do not produce significant estimates (at the 10\% level). The formula specification of the full model is hidden here for brevity
%
<<hidden, echo=FALSE>>=
f_full <- wfh | log_weekly_km ~
  age + educ_higher + hh_income + young_kids + workload + fixed_workplace +
  shift_work + permanent_employed + isco_craft + isco_tech + isco_clerical +
  isco_elementary + car_access + parking_home + freq_onl_order +
  grocery_shopper |
  sex_male + age + educ_higher + swiss + married + res_loc + dogs + hh_size +
  young_kids + n_children + workload + fixed_workplace + permanent_employed +
  driverlicense + car_access + parking_home + parking_work + rents_home +
  freq_onl_order + vacation + grocery_shopper |
  sex_male + age + educ_higher + swiss + married + res_loc + dogs + hh_size +
  young_kids + n_children + workload + fixed_workplace + permanent_employed +
  driverlicense + car_access + parking_home + parking_work + rents_home +
  freq_onl_order + vacation + grocery_shopper |
  sex_male + age + educ_higher + swiss + married + res_loc + dogs + hh_size +
  young_kids + n_children + workload + fixed_workplace + permanent_employed +
  driverlicense + car_access + parking_work + rents_home +
  freq_onl_order + vacation + grocery_shopper
@
%
<<full-reduced>>=
fit_full <- opsr(f_full, timeuse_data, printLevel = 0)
f_red <- wfh | log_weekly_km ~
  age + educ_higher + hh_income + young_kids + workload + fixed_workplace +
  shift_work + permanent_employed + isco_craft + isco_tech + isco_clerical +
  isco_elementary + car_access + parking_home + freq_onl_order +
  grocery_shopper |
  sex_male + res_loc + workload + permanent_employed + parking_work |
  swiss + res_loc + young_kids + workload + parking_work |
  sex_male + swiss + fixed_workplace + permanent_employed + parking_work

fit_red <- opsr(f_red, timeuse_data, printLevel = 0)
print(anova(fit_red, fit_full), print.formula = FALSE)
summary(fit_red)
@
%
We see that our reduced model specification is not rejected in the likelihood ratio test. Further, there is significant error correlation between the error of the selection process and the error of the outcome process for the UTW (\code{rho3}). The Wald-test suggests that the Null hypothesis (\code{rho1} = \code{rho2} = \code{rho3} = 0) can be rejected at the 5\% level, hinting that OPSR is beneficial given our model specification.

However, so far we have neglected the commute distance which most likely impacts the propensity to telework (see Figure~\ref{fig:boxplot}) and naturally influences the weekly distance driven. To illustrate this, we simply add \code{log_weekly_km} to our reduced model specification
%
<<adding-commute>>=
fit_commute <- update(fit_red, ~ . + log_commute_km | . + log_commute_km | . +
  log_commute_km | . + log_commute_km)

cat("Wald chi2 (rho):", round(summary(fit_commute)$wald$rho$pval, 2))

texreg::screenreg(list(fit_red, fit_commute), include.R2 = TRUE,
  include.pseudoR2 = TRUE)
@
%
where now all goodness of fit indicators improved (in particular R$^2$ for the continuous outcomes) and the rho coefficients are no longer significant at conventional levels. Similarly, the Wald-test (rho) can not reject the Null. At the same time some of the coefficients slightly changed in magnitude and rendered insignificant or vice versa. For example, the effect of residential location (\code{o1_res_loc_rural} and \code{o2_res_loc_rural}) moderated the effect of commute distance in \code{fit_red}.

While this discussion (of how to deal with potentially endogenous variables) is common for all regression analysis, it demonstrates here how error correlation can occur and why it might be important to account for. Both model specifications (\code{fit_red} and \code{fit_commute}) produce almost identical insights in the post-estimation that follows and we proceed with the latter model.

%% The treatment effects

\begin{leftbar}
daniehei: 1. Compute average treatment effects, 2. Graphic, 3. Scatter plot, 4. Unit treatment effects
\end{leftbar}


%% -- Summary/conclusions/discussion -------------------------------------------

\section{Summary and discussion} \label{sec:summary}


%% -- Optional special unnumbered sections -------------------------------------

\section*{Computational details}

The results in this paper were obtained using
\proglang{R}~\Sexpr{paste(R.Version()[6:7], collapse = ".")} with the
\pkg{OPSR}~\Sexpr{packageVersion("OPSR")} package. \proglang{R} itself
and all packages used are available from the Comprehensive
\proglang{R} Archive Network (CRAN) at
\url{https://CRAN.R-project.org/}.


\section*{Acknowledgments}


%% -- Bibliography -------------------------------------------------------------
%% - References need to be provided in a .bib BibTeX database.
%% - All references should be made with \cite, \citet, \citep, \citealp etc.
%%   (and never hard-coded). See the FAQ for details.
%% - JSS-specific markup (\proglang, \pkg, \code) should be used in the .bib.
%% - Titles in the .bib should be in title case.
%% - DOIs should be included where available.

\bibliography{refs}


%% -- Appendix (if any) --------------------------------------------------------
%% - After the bibliography with page break.
%% - With proper section titles and _not_ just "Appendix".

\newpage

% \begin{appendix}
%
% \section{More technical details} \label{app:technical}
%
%
% \end{appendix}

%% -----------------------------------------------------------------------------


\end{document}
